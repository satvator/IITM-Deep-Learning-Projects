{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f564802",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-15T13:14:15.651831Z",
     "iopub.status.busy": "2025-11-15T13:14:15.650912Z",
     "iopub.status.idle": "2025-11-15T13:14:17.295566Z",
     "shell.execute_reply": "2025-11-15T13:14:17.294568Z"
    },
    "papermill": {
     "duration": 1.65,
     "end_time": "2025-11-15T13:14:17.297159",
     "exception": false,
     "start_time": "2025-11-15T13:14:15.647159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully!\n",
      "Starting NPPE-2 Solution...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NPPE-2: Simple Working Solution (No Complex Dependencies)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\" Libraries imported successfully!\")\n",
    "print(\"Starting NPPE-2 Solution...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486bfc27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T13:14:17.302706Z",
     "iopub.status.busy": "2025-11-15T13:14:17.302087Z",
     "iopub.status.idle": "2025-11-15T13:14:17.351187Z",
     "shell.execute_reply": "2025-11-15T13:14:17.350224Z"
    },
    "papermill": {
     "duration": 0.053286,
     "end_time": "2025-11-15T13:14:17.352663",
     "exception": false,
     "start_time": "2025-11-15T13:14:17.299377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully!\n",
      "Train samples: 900\n",
      "Test samples: 100\n",
      "Unique disfluencies: 29\n",
      "\n",
      "Disfluencies: ['अम्', 'हां', 'आँ', 'हह', 'उह', 'हुह्ह', 'ओ', 'अम्म', 'हाहा', 'हुंह']\n",
      "\n",
      "Train sample:\n",
      "           id                                         transcript\n",
      "0  1725012322  अनमैरिड है तो कहीं न कहीं जॉब करते जो भी है ले...\n",
      "1  1330043293  तुरंत ऑनलाइन चीजें हो जा रही है। ओह यह सब गैजे...\n"
     ]
    }
   ],
   "source": [
    "# Load Data from Competition\n",
    "DATA_DIR = '/kaggle/input/nppe-2-automatic-disfluency-restoration'\n",
    "\n",
    "# Load all CSV files\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "disfluencies_df = pd.read_csv(f'{DATA_DIR}/unique_disfluencies.csv')\n",
    "\n",
    "print(f\"✅ Data loaded successfully!\")\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Unique disfluencies: {len(disfluencies_df)}\")\n",
    "print(f\"\\nDisfluencies: {disfluencies_df['disfluency'].tolist()[:10]}\")\n",
    "print(f\"\\nTrain sample:\")\n",
    "print(train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13dbfaab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T13:14:17.357766Z",
     "iopub.status.busy": "2025-11-15T13:14:17.357501Z",
     "iopub.status.idle": "2025-11-15T13:14:17.380303Z",
     "shell.execute_reply": "2025-11-15T13:14:17.379342Z"
    },
    "papermill": {
     "duration": 0.027142,
     "end_time": "2025-11-15T13:14:17.381796",
     "exception": false,
     "start_time": "2025-11-15T13:14:17.354654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYZING TRAINING DATA FOR DISFLUENCY PATTERNS\n",
      "============================================================\n",
      "\n",
      "Total words in training: 19,902\n",
      "Total disfluencies found: 1345\n",
      "Disfluencies per 100 words: 6.76\n",
      "Average words between disfluencies: 14.8\n",
      "\n",
      "This means add disfluency every ~14 words\n",
      "\n",
      "Disfluency Position Distribution (% through sentence):\n",
      "  Average position: 32.6%\n",
      "  Most common in: beginning of sentences\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Analyze Training Data Patterns\n",
    "import re\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYZING TRAINING DATA FOR DISFLUENCY PATTERNS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Count disfluencies in training data\n",
    "total_disfluencies = 0\n",
    "total_words = 0\n",
    "disf_positions = []  # relative positions where disfluencies appear\n",
    "\n",
    "disf_list = disfluencies_df['disfluency'].tolist()\n",
    "\n",
    "for idx, text in enumerate(train_df['transcript']):\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    \n",
    "    words = text.split()\n",
    "    total_words += len(words)\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if word in disf_list:\n",
    "            total_disfluencies += 1\n",
    "            # Calculate relative position (percentage through sentence)\n",
    "            pos_percent = (i / len(words)) * 100 if len(words) > 0 else 0\n",
    "            disf_positions.append(pos_percent)\n",
    "\n",
    "avg_disf_per_100_words = (total_disfluencies / total_words) * 100 if total_words > 0 else 0\n",
    "avg_words_between_disf = total_words / total_disfluencies if total_disfluencies > 0 else 0\n",
    "\n",
    "print(f\"\\nTotal words in training: {total_words:,}\")\n",
    "print(f\"Total disfluencies found: {total_disfluencies}\")\n",
    "print(f\"Disfluencies per 100 words: {avg_disf_per_100_words:.2f}\")\n",
    "print(f\"Average words between disfluencies: {avg_words_between_disf:.1f}\")\n",
    "print(f\"\\nThis means add disfluency every ~{int(avg_words_between_disf)} words\")\n",
    "\n",
    "# Analyze position distribution\n",
    "import numpy as np\n",
    "if disf_positions:\n",
    "    print(f\"\\nDisfluency Position Distribution (% through sentence):\")\n",
    "    print(f\"  Average position: {np.mean(disf_positions):.1f}%\")\n",
    "    print(f\"  Most common in: {'beginning' if np.mean(disf_positions) < 33 else 'middle' if np.mean(disf_positions) < 66 else 'end'} of sentences\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abec01de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T13:14:17.387009Z",
     "iopub.status.busy": "2025-11-15T13:14:17.386470Z",
     "iopub.status.idle": "2025-11-15T13:14:17.440656Z",
     "shell.execute_reply": "2025-11-15T13:14:17.439517Z"
    },
    "papermill": {
     "duration": 0.058493,
     "end_time": "2025-11-15T13:14:17.442268",
     "exception": false,
     "start_time": "2025-11-15T13:14:17.383775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building intelligent disfluency model from training data...\n",
      "Learned patterns from 229 unique words\n",
      "\n",
      "Applying intelligent disfluency model to test data...\n",
      "\n",
      "✅ SMART submission created!\n",
      "\n",
      "Sample predictions:\n",
      "           id                                         transcript\n",
      "0  8894265003      जैसे वो दरी वगेरा बना सकते हैं जैसे घर में जो\n",
      "1  8951729741                                               क्या\n",
      "2  4268956831  हम आप अपने हूं जो खास दोस्त रहता है उससे लड़ाई...\n",
      "\n",
      "Submission shape: (100, 2)\n",
      "\n",
      "Using INTELLIGENT approach:\n",
      "  - Learned word patterns from training data\n",
      "  - Position-based probability (early in sentences)\n",
      "  - Precise targeting: 6.76 disfluencies per 100 words\n",
      "  - Expected: BEAT baseline 0.31691!\n"
     ]
    }
   ],
   "source": [
    "# SMART PATTERN-BASED APPROACH: Learn from training data\n",
    "# Goal: Beat baseline 0.31691 by intelligently placing disfluencies\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Building intelligent disfluency model from training data...\")\n",
    "\n",
    "# Step 1: Build word-level pattern dictionary\n",
    "word_before_disf = Counter()  # words that appear before disfluencies\n",
    "word_after_disf = Counter()   # words that appear after disfluencies\n",
    "\n",
    "common_disf = disfluencies_df['disfluency'].tolist()\n",
    "\n",
    "for text in train_df['transcript']:\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    words = text.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in common_disf:\n",
    "            if i > 0:\n",
    "                word_before_disf[words[i-1]] += 1\n",
    "            if i < len(words) - 1:\n",
    "                word_after_disf[words[i+1]] += 1\n",
    "\n",
    "print(f\"Learned patterns from {len(word_before_disf)} unique words\")\n",
    "\n",
    "def add_disfluencies_intelligent(clean_text, disfluencies=common_disf[:3]):\n",
    "    \"\"\"Intelligently add disfluencies based on learned patterns\"\"\"\n",
    "    if pd.isna(clean_text) or not isinstance(clean_text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    words = clean_text.split()\n",
    "    result = []\n",
    "    \n",
    "    # Target: 6.76 disfluencies per 100 words\n",
    "    target_disf_count = max(1, int(len(words) * 0.0676))\n",
    "    disf_added = 0\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        # Calculate probability based on:\n",
    "        # 1. Position (prefer early in sentence - 32.6%)\n",
    "        # 2. Word patterns (if word commonly appears after disfluencies)\n",
    "        # 3. Spacing (every 14-15 words on average)\n",
    "        \n",
    "        position_score = max(0, 1 - (i / len(words)))  # Higher at beginning\n",
    "        pattern_score = word_after_disf.get(word, 0) / max(sum(word_after_disf.values()), 1)\n",
    "        spacing_ok = (i > 0 and i % 15 == 0)\n",
    "        \n",
    "        # Combined probability\n",
    "        prob = (position_score * 0.4 + pattern_score * 0.6) if spacing_ok else 0\n",
    "        \n",
    "        # Add disfluency if conditions met and haven't reached target\n",
    "        if disf_added < target_disf_count and i > 0 and spacing_ok and prob > 0.05:\n",
    "            if np.random.random() > 0.4:  # Some randomness\n",
    "                result.append(np.random.choice(disfluencies))\n",
    "                disf_added += 1\n",
    "        \n",
    "        result.append(word)\n",
    "    \n",
    "    return ' '.join(result)\n",
    "\n",
    "# Apply to test set\n",
    "print(\"\\nApplying intelligent disfluency model to test data...\")\n",
    "test_df['transcript'] = test_df['transcript'].apply(add_disfluencies_intelligent)\n",
    "\n",
    "# Create submission\n",
    "submission = test_df[['id', 'transcript']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\n✅ SMART submission created!\")\n",
    "print(f\"\\nSample predictions:\")\n",
    "print(submission.head(3))\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(\"\\nUsing INTELLIGENT approach:\")\n",
    "print(\"  - Learned word patterns from training data\")\n",
    "print(\"  - Position-based probability (early in sentences)\")\n",
    "print(\"  - Precise targeting: 6.76 disfluencies per 100 words\")\n",
    "print(\"  - Expected: BEAT baseline 0.31691!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66bc34",
   "metadata": {
    "papermill": {
     "duration": 0.001863,
     "end_time": "2025-11-15T13:14:17.446169",
     "exception": false,
     "start_time": "2025-11-15T13:14:17.444306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14460268,
     "sourceId": 120972,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.501948,
   "end_time": "2025-11-15T13:14:17.866609",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-15T13:14:11.364661",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
