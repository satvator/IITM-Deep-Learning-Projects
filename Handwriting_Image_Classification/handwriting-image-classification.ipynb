{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T19:27:30.095152Z","iopub.execute_input":"2025-12-12T19:27:30.095474Z","iopub.status.idle":"2025-12-12T19:27:30.099406Z","shell.execute_reply.started":"2025-12-12T19:27:30.095451Z","shell.execute_reply":"2025-12-12T19:27:30.098488Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport copy\n\n# ==========================================\n# 1. CONFIGURATION\n# ==========================================\nBASE_DIR = '/kaggle/input/dlp-image-classification-for-handwriting/downlaod1'\nTRAIN_CSV_PATH = os.path.join(BASE_DIR, 'train.csv')\nTEST_DIR = os.path.join(BASE_DIR, 'test')\nSAMPLE_SUB_PATH = os.path.join(BASE_DIR, 'sample_submission.csv')\nTRAIN_DIR = os.path.join(BASE_DIR, 'train') \n\n# High Resolution & EfficientNet B1\nIMG_SIZE = 256 \nBATCH_SIZE = 32\nLEARNING_RATE = 0.0005 \nEPOCHS = 15\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"Using device: {DEVICE} | Model: EfficientNet B1 | Res: {IMG_SIZE}x{IMG_SIZE}\")\n\n# ==========================================\n# 2. DATASET\n# ==========================================\nclass HandwritingDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, is_test=False):\n        self.data = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = self.data.iloc[idx, 0]\n        img_path = os.path.join(self.img_dir, img_name)\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n        except FileNotFoundError:\n            image = Image.open(os.path.join(BASE_DIR, img_name)).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.is_test:\n            return image, img_name\n        else:\n            label = int(self.data.iloc[idx, 1])\n            return image, label\n\n# ==========================================\n# 3. AUGMENTATION\n# ==========================================\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        # Random rotations and shifts to mimic handwriting variance\n        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.85, 1.15)), \n        transforms.ColorJitter(brightness=0.1, contrast=0.1), \n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# ==========================================\n# 4. PREPARE DATA (Fixed Split)\n# ==========================================\nfull_train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n# Use exactly 20 images for validation. \n# This ensures we have enough slots for all 10 classes (0-9).\ntrain_df, val_df = train_test_split(full_train_df, test_size=20, stratify=full_train_df['label'], random_state=42)\n\nprint(f\"Training on {len(train_df)} samples. Validation on {len(val_df)} samples.\")\n\ntrain_ds = HandwritingDataset(train_df, TRAIN_DIR, transform=data_transforms['train'])\nval_ds = HandwritingDataset(val_df, TRAIN_DIR, transform=data_transforms['val'])\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n# ==========================================\n# 5. MODEL: EFFICIENTNET B1\n# ==========================================\n# We use the 'models' module imported at the top to avoid import syntax errors\nmodel = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.DEFAULT)\n\n# Adjust Classifier for 10 classes\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\nmodel = model.to(DEVICE)\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=EPOCHS, T_mult=1)\n\n# ==========================================\n# 6. TRAINING LOOP\n# ==========================================\ndef train_model(model, epochs):\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        # Training Phase\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n        for inputs, labels in pbar:\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item() * inputs.size(0)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n            \n            pbar.set_postfix({'loss': loss.item()})\n        \n        scheduler.step()\n        \n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = correct / total\n        \n        print(f\"Epoch {epoch+1} | Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}\")\n\n    print(\"Training Complete.\")\n    return model\n\n# Train\nmodel = train_model(model, EPOCHS)\n\n# ==========================================\n# 7. SUBMISSION\n# ==========================================\nsample_sub = pd.read_csv(SAMPLE_SUB_PATH)\ntest_ds = HandwritingDataset(sample_sub, TEST_DIR, transform=data_transforms['val'], is_test=True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nprint(\"\\nGenerating predictions...\")\nmodel.eval()\n\nsubmission_rows = []\nwith torch.no_grad():\n    for inputs, img_names in tqdm(test_loader):\n        inputs = inputs.to(DEVICE)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        preds_list = preds.cpu().numpy()\n        \n        for img_name, pred in zip(img_names, preds_list):\n            submission_rows.append({'image_id': img_name, 'label': pred})\n\nsubmission_df = pd.DataFrame(submission_rows)\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Saved 'submission_b1_fixed.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T19:27:30.100492Z","iopub.execute_input":"2025-12-12T19:27:30.100727Z","iopub.status.idle":"2025-12-12T19:29:38.391231Z","shell.execute_reply.started":"2025-12-12T19:27:30.100711Z","shell.execute_reply":"2025-12-12T19:29:38.390467Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b1-c27df63c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1-c27df63c.pth\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda | Model: EfficientNet B1 | Res: 256x256\nTraining on 910 samples. Validation on 20 samples.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30.1M/30.1M [00:00<00:00, 193MB/s]\n                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 2.0342 | Train Acc: 0.3473\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 0.9204 | Train Acc: 0.8989\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 0.6281 | Train Acc: 0.9714\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 0.5678 | Train Acc: 0.9923\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 0.5545 | Train Acc: 0.9901\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 0.5427 | Train Acc: 0.9923\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 0.5341 | Train Acc: 0.9956\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 0.5240 | Train Acc: 0.9978\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 0.5278 | Train Acc: 0.9945\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.5286 | Train Acc: 0.9945\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | Train Loss: 0.5282 | Train Acc: 0.9945\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | Train Loss: 0.5198 | Train Acc: 0.9978\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | Train Loss: 0.5204 | Train Acc: 0.9967\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | Train Loss: 0.5166 | Train Acc: 0.9978\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | Train Loss: 0.5189 | Train Acc: 0.9956\nTraining Complete.\n\nGenerating predictions...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:01<00:00, 10.89it/s]","output_type":"stream"},{"name":"stdout","text":"Saved 'submission_b1_fixed.csv'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6}]}